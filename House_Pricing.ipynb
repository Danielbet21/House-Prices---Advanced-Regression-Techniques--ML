{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries like pandas, matplotlib, seaborn, sklearn, plotly\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set all the necessary configurations for the graphs\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_palette(\"muted\")\n",
    "plt.figure(figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input and folder paths for the data\n",
    "input_folder = \"house-prices-advanced-regression-techniques/\"\n",
    "\n",
    "train_data_path = os.path.join(input_folder,\"train.csv\")\n",
    "test_data_path = os.path.join(input_folder,\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Loading the Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Droping the Id feature from the train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_id = train_data['Id']\n",
    "test_data_id = test_data['Id']\n",
    "train_data.drop('Id', axis=1, inplace=True)\n",
    "test_data.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the number of feuatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 80\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {train_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: <br> *Analyzing the data - EDA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Get the data types of the columns in the training dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     588 non-null    object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 912.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data is from type Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "-----------------------------------------\n",
      "Total Rows:  1460\n",
      "_________________________________________\n",
      "              Missing Values  Percentage\n",
      "PoolQC                  1453   99.520548\n",
      "MiscFeature             1406   96.301370\n",
      "Alley                   1369   93.767123\n",
      "Fence                   1179   80.753425\n",
      "MasVnrType               872   59.726027\n",
      "FireplaceQu              690   47.260274\n",
      "LotFrontage              259   17.739726\n",
      "GarageYrBlt               81    5.547945\n",
      "GarageCond                81    5.547945\n",
      "GarageType                81    5.547945\n",
      "GarageFinish              81    5.547945\n",
      "GarageQual                81    5.547945\n",
      "BsmtExposure              38    2.602740\n",
      "BsmtFinType2              38    2.602740\n",
      "BsmtCond                  37    2.534247\n",
      "BsmtQual                  37    2.534247\n",
      "BsmtFinType1              37    2.534247\n",
      "MasVnrArea                 8    0.547945\n",
      "Electrical                 1    0.068493\n",
      "MSSubClass                 0    0.000000\n",
      "\n",
      "\n",
      "Total missing values:  7829\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_missing_values_stat(data):\n",
    "    print(\"Missing values in the dataset:\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Total Rows: \", len(data))\n",
    "    print(\"_________________________________________\")\n",
    "    # Display missing values in each column of the training dataset\n",
    "    missing_values = data.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(train_data)) * 100\n",
    "    missing_data = pd.concat([missing_values, missing_percentage], axis=1, keys=['Missing Values', 'Percentage'])\n",
    "    missing_data.sort_values(by='Missing Values', ascending=False, inplace=True)\n",
    "    print(missing_data.head(20))\n",
    "    \n",
    "    print(\"\\n\\nTotal missing values: \", missing_data['Missing Values'].sum())\n",
    "    print(\"-----------------------------------------\")\n",
    "\n",
    "    \n",
    "    \n",
    "show_missing_values_stat(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can see that there are missing values in all the features above :\n",
    "* LotFrontage - 259 \n",
    "* Alley - 1369 \n",
    "* MasVnrType - 872 <br>.<br>.<br>.\n",
    "* MiscFeature - 1406\n",
    "\n",
    "Total of *19* features with missing values\n",
    "- 3 of float64\n",
    "- 16 of object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - we can see that a lot of the data is missing hance it's will be very hard to fill the missing part and might give us a false information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_highly_missing_features(data, fetures_to_drop):\n",
    "    data = data.drop(fetures_to_drop, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_features_with_missing_values_threshold(data, threshold):\n",
    "    missing_values = data.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(train_data)) * 100\n",
    "    missing_data = pd.concat([missing_values, missing_percentage], axis=1, keys=['Missing Values', 'Percentage'])\n",
    "    missing_data.sort_values(by='Missing Values', ascending=False, inplace=True)\n",
    "    features_to_drop = missing_data[missing_data['Percentage'] > threshold].index\n",
    "    return features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove this features:  Index(['PoolQC', 'MiscFeature', 'Alley', 'Fence'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold for missing values to remove\n",
    "threshold = 80\n",
    "# for 80 it return # [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\n",
    "drop_features = find_features_with_missing_values_threshold(train_data, threshold) \n",
    "\n",
    "\n",
    "train_data = drop_highly_missing_features(train_data, drop_features)\n",
    "\n",
    "test_data = drop_highly_missing_features(test_data, drop_features)\n",
    "\n",
    "print(\"Remove this features: \", drop_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Check the impact of dropping features that have less than 20% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "-----------------------------------------\n",
      "Total Rows:  1460\n",
      "_________________________________________\n",
      "              Missing Values  Percentage\n",
      "MasVnrType               872   59.726027\n",
      "FireplaceQu              690   47.260274\n",
      "LotFrontage              259   17.739726\n",
      "GarageType                81    5.547945\n",
      "GarageYrBlt               81    5.547945\n",
      "GarageFinish              81    5.547945\n",
      "GarageQual                81    5.547945\n",
      "GarageCond                81    5.547945\n",
      "BsmtExposure              38    2.602740\n",
      "BsmtFinType2              38    2.602740\n",
      "BsmtQual                  37    2.534247\n",
      "BsmtCond                  37    2.534247\n",
      "BsmtFinType1              37    2.534247\n",
      "MasVnrArea                 8    0.547945\n",
      "Electrical                 1    0.068493\n",
      "Fireplaces                 0    0.000000\n",
      "KitchenQual                0    0.000000\n",
      "KitchenAbvGr               0    0.000000\n",
      "BedroomAbvGr               0    0.000000\n",
      "HalfBath                   0    0.000000\n",
      "\n",
      "\n",
      "Total missing values:  2422\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "show_missing_values_stat(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *separate the numerical and categorical columns* ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = train_data.select_dtypes(include=[np.number])\n",
    "train_data_cat = train_data.select_dtypes(include=[object])\n",
    "\n",
    "test_data_num = test_data.select_dtypes(include=[np.number])\n",
    "test_data_cat = test_data.select_dtypes(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: <br>*Handling Missing Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *use a heat map on the numerical data to see the correlation between the features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graphs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changeeeeeeeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sw\n",
    "if False:\n",
    "    usedcars_report = sw.analyze(train_data)\n",
    "    usedcars_report.show_notebook(layout='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_corr_mat(df):\n",
    "    corr_matrix = df.corr()\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\")\n",
    "    plt.show()\n",
    "\n",
    "if show_graphs:\n",
    "    show_corr_mat(train_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low correaltion features: \n",
    " <br>LowQualFinSF----0.03\n",
    " <br>MiscVal-----------0.02\n",
    " <br>MiscVal-----------0.02\n",
    " <br>BsmtFinType2-----0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_from_data_set(df, cols: list):\n",
    "    df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 33)\n",
      "(1460, 34)\n"
     ]
    }
   ],
   "source": [
    "drop_from_data_set(test_data_num, [\"LowQualFinSF\",\"MiscVal\",\"MiscVal\",\"BsmtFinSF2\"])\n",
    "drop_from_data_set(train_data_num, [\"LowQualFinSF\",\"MiscVal\",\"MiscVal\",\"BsmtFinSF2\"])\n",
    "print(test_data_num.shape)\n",
    "print(train_data_num.shape)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The diffrence between the number of features is beacuse the test_data doesn't have the SalePrice feature in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    show_corr_mat(train_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Handling Missing Values for Numerical Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing numerical values with median\n",
    "def handle_missing_values_numerical(data):\n",
    "    for column in data.select_dtypes(include=[np.number]).columns:\n",
    "        data[column] = data[column].fillna(data[column].mean()) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Handling Missing Values for Categorical Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing categorical values with most frequent value\n",
    "def handle_missing_values_categorical(data):\n",
    "    for column in data.select_dtypes(include=[object]).columns:\n",
    "        data[column] = data[column].fillna(data[column].mode()[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = handle_missing_values_numerical(train_data_num)\n",
    "train_data_cat = handle_missing_values_categorical(train_data_cat)\n",
    "\n",
    "test_data_num = handle_missing_values_numerical(test_data_num)\n",
    "test_data_cat = handle_missing_values_categorical(test_data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the training dataset after filling:\n",
      "0\n",
      "\n",
      "Missing values in the test dataset after filling:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in the training dataset after filling:\")\n",
    "print(train_data_num.isnull().sum().sum() + train_data_cat.isnull().sum().sum())\n",
    "\n",
    "\n",
    "print(\"\\nMissing values in the test dataset after filling:\")\n",
    "print(test_data_num.isnull().sum().sum() + test_data_cat.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 73)\n",
      "(1459, 72)\n"
     ]
    }
   ],
   "source": [
    "# Combine the datasets to ensure consistent one-hot encoding\n",
    "train_data = pd.concat([train_data_cat, train_data_num], axis=1)\n",
    "test_data = pd.concat([test_data_cat, test_data_num], axis=1)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: <br> *Data Visualizing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Distribution of SalePrice*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if show_graphs:\n",
    "    plt.figure(figsize=(11, 7))\n",
    "    sns.histplot(train_data['SalePrice'], kde=True, bins=30, color='blue')\n",
    "    plt.title('Distribution of SalePrice')\n",
    "    plt.xlabel('SalePrice')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Histogram for SalePrice*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    fig = px.histogram(train_data, x='SalePrice', title='Distribution of SalePrice')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "if show_graphs:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    stats.probplot(train_data['SalePrice'], dist=\"norm\", plot=plt)\n",
    "    plt.title('Normal Probability Plot of SalePrice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    train_data_num.hist(bins=50, figsize=(22, 25))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def show_top_correlated_features(correlation_matrix, n):\n",
    "    # Display the heatmap of the correlation matrix with numbers in each cell\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.columns,\n",
    "        colorscale='Viridis',\n",
    "        text=correlation_matrix.values.round(2),  # Round values for display\n",
    "        texttemplate=\"%{text}\",\n",
    "        showscale=True))\n",
    "    fig.update_layout(title=f\"Top {n} Correlated Features\", width=1000, height=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    # Split the data to numerical and categorical columns\n",
    "    numerical_columns = train_data.select_dtypes(include=[\"int64\", 'float64']).columns\n",
    "    categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "\n",
    "    # Encode the categorical columns\n",
    "    categorical_columns_encoded = pd.get_dummies(train_data[categorical_columns])\n",
    "\n",
    "    # Combine the numerical and encoded categorical columns\n",
    "    train_data_encoded = pd.concat([train_data[numerical_columns], categorical_columns_encoded], axis=1)\n",
    "    # Create a correlation matrix\n",
    "    correlation_matrix = train_data_encoded.corr().abs()\n",
    "    N = 20\n",
    "    # Get the top N correlated features with the target variable\n",
    "    top_correlated_features = correlation_matrix['SalePrice'].sort_values(ascending=False).head(N).index.tolist()\n",
    "\n",
    "    # Filter the correlation matrix to get the top N correlated features\n",
    "    filtered_correlation_matrix = correlation_matrix.loc[top_correlated_features, top_correlated_features]\n",
    "    show_top_correlated_features(filtered_correlation_matrix, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4:<br>  *Feature Engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Square Footage\n",
    "\n",
    "- We create a new feature TotalSF by summing up the total basement square footage, first floor square footage, second floor square footage, and garage area. This feature represents the total square footage of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_engineering_list = []\n",
    "\n",
    "# create TotalSF feature\n",
    "def create_TotalSF_feature(data, features_engineering_list=None):\n",
    "    data['TotalSqureF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF'] + data['GarageArea']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalSqureF')\n",
    "    return data\n",
    "\n",
    "# Create the TotalSF feature for the train and test data\n",
    "train_data = create_TotalSF_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalSF_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Age of the House*\n",
    "\n",
    "- We calculate the age of the house at the time of sale by subtracting the year the house was built from the year it was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age_of_house feature\n",
    "def create_age_of_house_feature(data, features_engineering_list=None):\n",
    "    data['AgeOfHouse'] = data['YrSold'] - data['YearBuilt']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('AgeOfHouse')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Create the AgeOfHouse feature for the train and test data\n",
    "train_data = create_age_of_house_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_age_of_house_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Total Bathrooms*\n",
    "\n",
    "- We create a new feature TotalBath by summing up the number of full and half bathrooms in the basement and above grade, with half bathrooms counted as 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TotalBath feature\n",
    "def create_TotalBath_feature(data, features_engineering_list=None):\n",
    "    data['TotalBath'] = data['FullBath'] + 0.5 * data['HalfBath'] + data['BsmtFullBath'] + 0.5 * data['BsmtHalfBath']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalBath')\n",
    "    return data\n",
    "\n",
    "# Create the TotalBath feature for the train and test data\n",
    "train_data = create_TotalBath_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalBath_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Age of the Renovation*\n",
    "\n",
    "- We calculate the age of the house since its most recent renovation by subtracting the year of the most recent renovation from the year it was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age_of_renovation feature\n",
    "def create_age_of_renovation_feature(data, features_engineering_list=None):\n",
    "    data['AgeOfRenovation'] = data['YrSold'] - data['YearRemodAdd']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('AgeOfRenovation')\n",
    "    return data\n",
    "\n",
    "# Create the AgeOfRenovation feature for the train and test data\n",
    "train_data = create_age_of_renovation_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_age_of_renovation_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Total Porch Area_\n",
    "\n",
    "- We create a new feature TotalPorchSF by summing up the area of all porch-related features, representing the total porch area of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TotalPorchSF feature\n",
    "def create_TotalPorchSF_feature(data, features_engineering_list=None):\n",
    "    data['TotalPorchSF'] = data['OpenPorchSF'] + data['EnclosedPorch'] + data['3SsnPorch'] + data['ScreenPorch']\n",
    "    if features_engineering_list is not None:\n",
    "        features_engineering_list.append('TotalPorchSF')\n",
    "    return data\n",
    "\n",
    "# Create the TotalPorchSF feature for the train and test data\n",
    "train_data = create_TotalPorchSF_feature(train_data, features_engineering_list)\n",
    "\n",
    "test_data = create_TotalPorchSF_feature(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Display the New Features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TotalSqureF  AgeOfHouse  TotalBath  AgeOfRenovation  TotalPorchSF\n",
      "0         3114           5        3.5                5            61\n",
      "1         2984          31        2.5               31             0\n",
      "2         3314           7        3.5                6            42\n",
      "3         3115          91        2.0               36           307\n",
      "4         4179           8        3.5                8            84\n"
     ]
    }
   ],
   "source": [
    "print(train_data[features_engineering_list].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_graphs:\n",
    "    N = 20\n",
    "    # Split the data to numerical and categorical columns\n",
    "    numerical_columns = train_data.select_dtypes(include=[\"int64\", 'float64']).columns\n",
    "    categorical_columns = train_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "\n",
    "    # Encode the categorical columns\n",
    "    categorical_columns_encoded = pd.get_dummies(train_data[categorical_columns])\n",
    "\n",
    "    # Combine the numerical and encoded categorical columns\n",
    "    train_data_encoded = pd.concat([train_data[numerical_columns], categorical_columns_encoded], axis=1)\n",
    "\n",
    "\n",
    "    # Create a correlation matrix\n",
    "    correlation_matrix = train_data_encoded.corr().abs()\n",
    "    \n",
    "    # Get the top N correlated features with the target variable\n",
    "    top_correlated_features = correlation_matrix['SalePrice'].sort_values(ascending=False).head(N).index.tolist()\n",
    "\n",
    "    # Filter the correlation matrix to get the top N correlated features\n",
    "    filtered_correlation_matrix = correlation_matrix.loc[top_correlated_features, top_correlated_features]\n",
    "    \n",
    "    show_top_correlated_features(filtered_correlation_matrix, N)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- concat the train and the test.\n",
    "### *Make the One-Hot-Encoding on the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 261)\n",
      "(1459, 260)\n"
     ]
    }
   ],
   "source": [
    "# get the SalePrice column\n",
    "sale_price = train_data['SalePrice']\n",
    "\n",
    "# Apply one-hot encoding\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "# Align the datasets to ensure consistent columns\n",
    "train_data, test_data = train_data.align(test_data, join='inner', axis=1)\n",
    "\n",
    "# Add the SalePrice column back to the training dataset\n",
    "train_data['SalePrice'] = sale_price\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5:<br> *Feature Selection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('SalePrice', axis=1)\n",
    "t = train_data['SalePrice']\n",
    "\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the nassacey library for RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "# len(train_data.columns)\n",
    "\n",
    "def featureSelection(model, train, target, val_data, val_target):\n",
    "    ref_select = RFE(model, n_features_to_select=3).fit(train, target)\n",
    "    ref_score = ref_select.score(val_data, val_target)\n",
    "    \n",
    "    for n in range(1, len(train_data.columns)):\n",
    "        ref = RFE(model, n_features_to_select=n).fit(train, target)\n",
    "        ref_score_test = ref.score(val_data, val_target)\n",
    "\n",
    "        if ref_score_test > ref_score:\n",
    "            ref_score = ref_score_test\n",
    "            ref_select = ref\n",
    "            \n",
    "    return ref_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *K-Fold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataToKFold(X, t, k):\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    result = []\n",
    "    \n",
    "    for i, (train_ids, val_ids) in enumerate(cv.split(X)):\n",
    "        X_train = X.loc[train_ids]\n",
    "        t_train = t.loc[train_ids]\n",
    "        X_val = X.loc[val_ids]\n",
    "        t_val = t.loc[val_ids]\n",
    "        \n",
    "        result.append({\"X_train\": X_train\n",
    "                      ,\"t_train\" : t_train\n",
    "                      ,\"X_val\": X_val\n",
    "                      ,\"t_val\": t_val\n",
    "                      })\n",
    "    return result\n",
    "    \n",
    "def margeCV(cv):\n",
    "    X_train = []\n",
    "    t_train = []    \n",
    "    X_val = []\n",
    "    t_val = []\n",
    "    \n",
    "    for i, d in enumerate(cv):\n",
    "            X_train.append(d[\"X_train\"])\n",
    "            t_train.append(d[\"t_train\"])\n",
    "            \n",
    "            X_val.append(d[\"X_val\"])\n",
    "            t_val.append(d[\"t_val\"])\n",
    "            \n",
    "    X_train = pd.concat(X_train) \n",
    "    t_train = pd.concat(t_train) \n",
    "    X_val = pd.concat(X_val) \n",
    "    t_val = pd.concat(t_val) \n",
    "    \n",
    "    return {\"X_train\": X_train,\n",
    "            \"t_train\": t_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"t_val\": t_val\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Home\\Desktop\\Machine_Learning\\House Prices\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+12, tolerance: 3.683e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# split to train and validation\n",
    "cv = splitDataToKFold(X, t, k=5)\n",
    "cv = margeCV(cv)\n",
    "\n",
    "# use lasso model\n",
    "model = Lasso(alpha=0.1)\n",
    "print(\"Done with Lasso\")\n",
    "# feature selection\n",
    "model = featureSelection(model, cv[\"X_train\"], cv[\"t_train\"], cv['X_val'], cv['t_val'])\n",
    "print(\"Done with feature selection\")\n",
    "model.fit(cv[\"X_train\"],cv[\"t_train\"])\n",
    "\n",
    "print(f\"Train Score: {model.score(cv['X_train'], cv['t_train'])}\\n\\\n",
    "Validation Score: {model.score(cv['X_val'], cv['t_val'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Prediction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "test_data[\"Id\"] = test_data_id\n",
    "output = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
